# -*- coding: utf-8 -*-
"""Mukhammad Fahlevi Ali Rafsanjani_Submission1_NLP_Belajar Pengembangan Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T9VFO2DwX2-YImFYZzRqofqWBun3t980

* Nama : Mukhammad Fahlevi Ali Rafsanjani
* Asal : Bandung
* Kelas: Studi Independen Machine Learning dan Front Ed Web
"""

from google.colab import drive

# u/ dataframe
import pandas as pd
import re


# u/ split data
from sklearn.model_selection import train_test_split

# u/ preprocessing dan layer
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

# u/ visualisasi plot
import matplotlib.pyplot as plt

pip install -q kaggle

from google.colab import files
files.upload()

# make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets list

!kaggle datasets download -d lokkagle/movie-genre-data

# unzip
!mkdir movie-genre-data
!unzip movie-genre-data.zip -d movie-genre-data
!ls movie-genre-data

import pandas as pd
import numpy as np

df=pd.read_csv('movie-genre-data/kaggle_movie_train.csv')
df

long_string= '============================================================================================='
def printByInformation(dataset,option=False):
  if option:
    pd.set_option('display.max_columns',None)
  print(f'Current Cols:{dataset.shape[1]}')
  print(f'Current Rows:{dataset.shape[0]}')
  print(long_string)
  print(f'Amount of NaNs: {dataset.isna().sum().sum()} the number of NaNs Found')
  print(long_string)
  print(f'Columns which has value NaN: {dataset.isna().sum()}')
  print(long_string)
  print(f'Column Name:{list(dataset.columns)}')
  print(long_string)
  print(f'{dataset.info()}')
  print(f'{dataset.describe()}')
printByInformation(df,True)

df.head(50)

import re

df.genre.value_counts()

df = df[~df['genre'].isin(['sci-fi','horror','other','adventure','romance'])]
df['genre'].value_counts()

# Menghapus special character di kolom text menggunakan re
df['Text'] = df['text'].map(lambda x: re.sub(r'\W+', ' ', x))
# drop kolom id dan text lama
df = df.drop(['id', 'text'], axis=1)
df.head()

#mengunbah teks menjadi dummy agar dapat di training
genre = pd.get_dummies(df.genre)
df_genre = pd.concat([df, genre], axis=1)
df_genre = df_genre.drop(columns='genre')
df_genre.head()

df_genre.info()

text = df_genre['Text'].astype(str)
label = df_genre[['action', 'comedy','drama','thriller']].values

text

label

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from sklearn.model_selection import train_test_split

genre_train, genre_test, label_train, label_test = train_test_split(text, label, test_size = 0.2)

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(genre_train) 
tokenizer.fit_on_texts(genre_test)
 
sekuens_train = tokenizer.texts_to_sequences(genre_train)
sekuens_test = tokenizer.texts_to_sequences(genre_test)
 
padded_train = pad_sequences(sekuens_train) 
padded_test = pad_sequences(sekuens_test)

model = Sequential([
    Embedding(input_dim=5000, output_dim=16),
    LSTM(64),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])

model.summary()

Adam(learning_rate=0.00146, name='Adam')
model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      print("\nAkurasi  di atas 97%, Training dihentikan!")
      self.model.stop_training = True

callbacks = myCallback()

num_epochs = 30
history = model.fit(padded_train, label_train, epochs=num_epochs, validation_data=(padded_test, label_test), verbose=1,callbacks=[callbacks])

# Plot Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

